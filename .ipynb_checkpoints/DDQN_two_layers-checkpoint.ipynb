{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import basics\n",
    "import misc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic = basics.Basics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic.define_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = basic.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ats = misc.make_attenuations(layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12397633241792705"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic.probability_error([actions[0][3], actions[1][3],actions[1][3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_memory):\n",
    "        self._max_memory = max_memory\n",
    "        self._samples = []\n",
    "    def add_sample(self, sample):\n",
    "        self._samples.append(sample)\n",
    "        if len(self._samples) > self._max_memory:\n",
    "            self._samples.pop(0)\n",
    "    def sample(self, no_samples):\n",
    "        if no_samples > len(self._samples):\n",
    "            return random.sample(self._samples, len(self._samples))\n",
    "        else:\n",
    "            return random.sample(self._samples, no_samples)\n",
    "    @property\n",
    "    def num_samples(self):\n",
    "        return len(self._samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality_betas = 100\n",
    "\n",
    "class QN_l1(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(QN_l1,self).__init__()\n",
    "        self.l1 = Dense(30, input_shape=(0,), kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "        self.l2 = Dense(35, kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "\n",
    "        # self.l21 = Dense(90, kernel_initializer='random_uniform',\n",
    "        #         bias_initializer='random_uniform')\n",
    "        self.l3 = Dense(cardinality_betas, kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "\n",
    "    def call(self, input):\n",
    "        feat = tf.nn.relu(self.l1(input))\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        # feat = tf.nn.relu(self.l21(feat))\n",
    "        value = self.l3(feat)\n",
    "        return value\n",
    "    \n",
    "    \n",
    "\n",
    "class QN_l2(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(QN_l2,self).__init__()\n",
    "        self.l1 = Dense(30, input_shape=(1,2), kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "        self.l2 = Dense(35, kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "\n",
    "        # self.l21 = Dense(90, kernel_initializer='random_uniform',\n",
    "        #         bias_initializer='random_uniform')\n",
    "        self.l3 = Dense(cardinality_betas, kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "\n",
    "    def call(self, input):\n",
    "        feat = tf.nn.relu(self.l1(input))\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        # feat = tf.nn.relu(self.l21(feat))\n",
    "        value = self.l3(feat)\n",
    "        return value\n",
    "    \n",
    "class QN_guess(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(QN_guess,self).__init__()\n",
    "        self.l1 = Dense(30, input_shape=(1,4), kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "        self.l2 = Dense(35, kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "\n",
    "        # self.l21 = Dense(90, kernel_initializer='random_uniform',\n",
    "        #         bias_initializer='random_uniform')\n",
    "        self.l3 = Dense(2, kernel_initializer='random_uniform',\n",
    "                bias_initializer='random_uniform')\n",
    "\n",
    "    def call(self, input):\n",
    "        feat = tf.nn.relu(self.l1(input))\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        # feat = tf.nn.relu(self.l21(feat))\n",
    "        value = self.l3(feat)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example give first Q-values for all actions... Notice it depends on the first input... it seems to be better with vacuum input... []\n",
    "\n",
    "BEGIN CHECKING INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 20:31:19.278671 140469290936128 base_layer.py:1865] Layer qn_l1_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.00074912  0.02600916 -0.02506557 -0.04781964 -0.00535387  0.0023195\n",
      "  -0.03180026  0.03898512  0.0392261   0.03314881 -0.0092338   0.04336263\n",
      "  -0.02974088  0.02258825 -0.03811301  0.03529671 -0.03043775 -0.00705362\n",
      "  -0.00059459  0.009857    0.03915123 -0.01151287  0.02802369 -0.03127613\n",
      "   0.02146689 -0.01572688  0.03820823 -0.01980803 -0.01710083  0.02081456\n",
      "   0.0013006   0.04109899 -0.01515364 -0.01326397 -0.00744298  0.02907929\n",
      "  -0.00031877 -0.02890212  0.03227521  0.03184559 -0.02529782  0.01759911\n",
      "  -0.02957401 -0.02480137 -0.03344799 -0.0475404   0.03087429  0.0373899\n",
      "  -0.01501742  0.01527805  0.0221046  -0.04054911 -0.0411677   0.02902752\n",
      "   0.02308889  0.00511522 -0.00605726 -0.03923258  0.03228486  0.02345083\n",
      "  -0.02650871 -0.00254951  0.03419234 -0.01683163 -0.03596905  0.01850432\n",
      "  -0.01544592  0.0393732   0.04488974 -0.00304188 -0.01428178 -0.00461878\n",
      "  -0.01892912  0.03985624 -0.03622999  0.01075823  0.01163258 -0.02058163\n",
      "   0.01596897 -0.03682679  0.03897233  0.02308309  0.01005376 -0.03869569\n",
      "   0.00933836 -0.03065974  0.02459738 -0.00193553  0.00929469 -0.04348274\n",
      "   0.04725125 -0.01169757 -0.03697127  0.03192444  0.03585223 -0.03725236\n",
      "   0.04443634 -0.03336824  0.03266001 -0.00736609]], shape=(1, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "qn_l1 = QN_l1()\n",
    "input = np.expand_dims( np.array([]), axis=0)\n",
    "print(qn_l1(input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 20:29:49.517792 140469290936128 base_layer.py:1865] Layer qn_l2_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0625212e-03 -4.2104911e-02 -4.4349033e-02  3.6907166e-02\n",
      "   2.9758589e-02  1.4581032e-02  1.8021340e-02 -2.4129953e-02\n",
      "  -3.0656625e-02 -6.2629534e-03  3.7051946e-02  1.9075744e-02\n",
      "   4.8119348e-02  1.3556759e-02  4.5132190e-03 -3.7624963e-02\n",
      "  -3.2285387e-03 -3.5262588e-02 -1.3067789e-02  2.0576989e-02\n",
      "   3.2979202e-02  4.2898372e-02  2.4125054e-02  1.6277252e-02\n",
      "  -2.4113718e-02 -3.9625656e-02  4.1379172e-02 -2.0514958e-02\n",
      "  -1.2627402e-02 -1.9148732e-02  4.1813344e-02 -3.9564278e-02\n",
      "  -2.9042082e-02 -3.8081001e-02  2.9851761e-02 -2.9009234e-02\n",
      "   3.8464431e-02  3.9809018e-02  6.8736356e-03 -3.7539680e-03\n",
      "   2.5110736e-02  2.9634666e-02  4.5806341e-02 -4.8223636e-03\n",
      "  -4.4943854e-02  4.3409732e-03 -1.8229170e-03 -2.6842337e-02\n",
      "  -3.4095261e-02 -3.2358807e-02 -2.4405716e-02  3.8465843e-02\n",
      "   3.6392089e-02  1.4897797e-03  8.4260069e-03  1.9480050e-02\n",
      "   3.8894277e-02  3.1570744e-02  3.3249196e-02 -2.9833205e-02\n",
      "   2.8647045e-02  4.1021168e-02 -1.3862589e-02  1.5522738e-02\n",
      "  -3.2188568e-02  3.6931697e-02 -3.9545033e-02  1.7080616e-02\n",
      "  -2.3280252e-02  4.4804320e-02  2.5618469e-02 -2.8408136e-02\n",
      "   4.9104139e-02  1.7140817e-02  1.2770686e-02 -5.0121048e-03\n",
      "  -7.0769517e-03  2.4408480e-02  2.8438952e-02 -8.3740763e-03\n",
      "  -1.8845767e-02 -2.8878460e-02 -2.9676834e-02  1.4526751e-02\n",
      "   1.9642467e-02  8.3538638e-03  4.0377680e-02  4.6575926e-02\n",
      "   2.2229217e-03 -2.3558054e-02 -2.9628850e-03  3.0979682e-02\n",
      "  -4.9459357e-03 -1.1050418e-02  3.9860092e-02  4.6989646e-02\n",
      "  -4.5201741e-05  3.0348564e-02 -4.6496309e-02 -3.2307960e-02]], shape=(1, 100), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.73409330e-03 -4.22824882e-02 -4.44572270e-02  3.63199972e-02\n",
      "   3.02541610e-02  1.49631687e-02  1.77728459e-02 -2.40536630e-02\n",
      "  -3.12030632e-02 -5.66195417e-03  3.69276516e-02  1.94622166e-02\n",
      "   4.82853986e-02  1.35213546e-02  4.72033443e-03 -3.74558084e-02\n",
      "  -2.49274634e-03 -3.53977084e-02 -1.30992625e-02  2.05423646e-02\n",
      "   3.29800807e-02  4.31354865e-02  2.34165136e-02  1.64187420e-02\n",
      "  -2.41557956e-02 -4.00439501e-02  4.14019860e-02 -2.02231370e-02\n",
      "  -1.31138051e-02 -1.93799455e-02  4.17752862e-02 -3.96757349e-02\n",
      "  -2.89442427e-02 -3.87014784e-02  3.00264228e-02 -2.89286710e-02\n",
      "   3.93489078e-02  4.05392051e-02  6.81724399e-03 -3.81411705e-03\n",
      "   2.42961105e-02  2.94246841e-02  4.53775190e-02 -5.37265185e-03\n",
      "  -4.52303551e-02  4.26171673e-03 -1.94725837e-03 -2.71788575e-02\n",
      "  -3.37568372e-02 -3.27109434e-02 -2.42621973e-02  3.84269617e-02\n",
      "   3.60996760e-02  2.08551111e-03  8.60018469e-03  1.97759904e-02\n",
      "   3.86072956e-02  3.14330794e-02  3.28457020e-02 -2.97660902e-02\n",
      "   2.89289821e-02  4.04896885e-02 -1.36800483e-02  1.53192841e-02\n",
      "  -3.21510993e-02  3.70213315e-02 -3.96811813e-02  1.69868376e-02\n",
      "  -2.35196184e-02  4.47326936e-02  2.60826629e-02 -2.84791067e-02\n",
      "   4.92939018e-02  1.72773637e-02  1.26756737e-02 -4.76735597e-03\n",
      "  -6.88221818e-03  2.37009637e-02  2.80202404e-02 -8.97286087e-03\n",
      "  -1.94476657e-02 -2.88085602e-02 -2.99065877e-02  1.47755072e-02\n",
      "   1.95096843e-02  8.27932917e-03  4.07610387e-02  4.63096350e-02\n",
      "   2.15386180e-03 -2.34858096e-02 -2.60773813e-03  3.13496552e-02\n",
      "  -5.19609079e-03 -1.09013151e-02  4.03562114e-02  4.71839644e-02\n",
      "   1.04070641e-05  3.04837059e-02 -4.59603965e-02 -3.20674144e-02]], shape=(1, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "qn_l2 = QN_l2()\n",
    "input = np.expand_dims( np.array([0,.8]), axis=0)\n",
    "print(qn_l2(input))\n",
    "input = np.expand_dims( np.array([1,.8]), axis=0)\n",
    "print(qn_l2(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 20:19:25.978965 140469290936128 base_layer.py:1865] Layer qn_guess_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.   0.  -0.7  0.7]], shape=(1, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.01704203, 0.02673172]], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qng = QN_guess()\n",
    "input = np.expand_dims(np.array([ 0., 0., -.7, .7  ] ) ,axis=0)\n",
    "qng(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF CHECKING INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how to be ep greedy with respect to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 20:31:24.576371 140469290936128 base_layer.py:1865] Layer qn_l1_37 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qn_l1 = QN_l1()\n",
    "input = np.expand_dims( np.array([]), axis=0)\n",
    "q1 = qn_l1(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1s = q1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03455481, -0.01170235, -0.04903212,  0.03421739,  0.0528808 ,\n",
       "         0.00525958,  0.01107826, -0.01987387, -0.03346476,  0.01991519,\n",
       "        -0.02900896,  0.01681749,  0.04260123,  0.03995398,  0.02402009,\n",
       "        -0.01783213, -0.00369048, -0.04528306,  0.05035957, -0.04076263,\n",
       "        -0.00512198, -0.00016955, -0.03052522, -0.0411858 ,  0.02732056,\n",
       "         0.04958795,  0.00553116,  0.04764386, -0.01107096, -0.00509022,\n",
       "        -0.03770528, -0.00056528,  0.02100876,  0.01279437,  0.03927073,\n",
       "         0.01397531,  0.01601703,  0.01414498,  0.04388795, -0.02447616,\n",
       "        -0.03036447,  0.03708176, -0.00076221, -0.00453608, -0.02963739,\n",
       "         0.01244547, -0.03610297, -0.0435673 , -0.01007746, -0.01713593,\n",
       "        -0.03422749,  0.0463099 ,  0.04414511, -0.01837685,  0.03315228,\n",
       "        -0.05380254, -0.02254123, -0.03564161,  0.02493927, -0.04122977,\n",
       "        -0.00441403, -0.00036001, -0.03097798, -0.01231195,  0.01716325,\n",
       "         0.02562855,  0.04383612,  0.00814868,  0.0378971 , -0.00647124,\n",
       "         0.04429306, -0.00713201,  0.03154496, -0.02574911, -0.02929702,\n",
       "         0.04372145, -0.00761121,  0.01417256,  0.02293532, -0.02636258,\n",
       "        -0.00473378, -0.01489965,  0.00555093,  0.03698164, -0.03531197,\n",
       "        -0.03558898,  0.03029641, -0.04079974, -0.03436493,  0.00985582,\n",
       "         0.03672901, -0.00947815, -0.03055068, -0.03125196, -0.04465856,\n",
       "         0.02650262, -0.03870437,  0.03217306, -0.00021444, -0.00017937]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(q1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1031 20:42:33.366122 140469290936128 base_layer.py:1865] Layer qn_l2_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qs2 = QN_l2()\n",
    "input = np.array([1., -.7])\n",
    "s2 = qs2( np.expand_dims(input, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "qn_l1_prim = QN_l1()\n",
    "qn_l1_targ = QN_l1()\n",
    "\n",
    "qn_l2_prim = QN_l2()\n",
    "qn_l2_targ = QN_l2()\n",
    "\n",
    "qn_guess_prim = QN_guess()\n",
    "qn_guess_targ = QN_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_first_beta():\n",
    "    if np.random.random() < epsilon:\n",
    "        beta1 = np.random.choice(basic.actions[0])\n",
    "        return beta1\n",
    "    else:\n",
    "        input = np.expand_dims(np.array([]), axis=0)\n",
    "        q1s = qn_l1_prim(input)\n",
    "        q1s = q1s.numpy()\n",
    "        label = np.argmax(q1s)\n",
    "        beta1 = basic.actions[0][label]\n",
    "        return beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_second_beta(new_state):\n",
    "    if np.random.random() < epsilon:\n",
    "        beta2 = np.random.choice(basic.actions[1][new_state[0]])\n",
    "        return beta2\n",
    "    else:\n",
    "        input = np.expand_dims(np.array(new_state), axis=0)\n",
    "        q2s = qn_l2_prim(input)\n",
    "        q2s = q2s.numpy()\n",
    "        label = np.argmax(q2s)\n",
    "        beta1 = basic.actions[1][new_state[0]][label]\n",
    "        return beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epsilon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-13abd970ec04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutcome1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-134-13abd970ec04>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_wasted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mphase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgive_first_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutcome1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-9fb287972988>\u001b[0m in \u001b[0;36mgive_first_beta\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgive_first_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mbeta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epsilon' is not defined"
     ]
    }
   ],
   "source": [
    "alpha = .56\n",
    "states_wasted = 10**4\n",
    "epsilon = 1\n",
    "def main():\n",
    "    for episode in range(states_wasted):\n",
    "        phase = np.random.choice([-1,1],1)[0]\n",
    "        beta1 = give_first_beta()\n",
    "        p0 = np.exp(-(beta1-(phase*np.cos(ats[0])*alpha))**2)\n",
    "        outcome1 = np.random.choice([0,1],1,p=[p0,1-p0])\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7000000000000001"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(basic.actions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22873532153458598"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .56\n",
    "states_wasted = 10**4\n",
    "\n",
    "def main():\n",
    "    for episode in range(states_wasted):\n",
    "        phase = np.random.choice([-1,1],1)[0]\n",
    "        beta1 = give_first_beta()\n",
    "        p0 = np.exp(-(beta1-(phase*np.cos(ats[0])*alpha))**2)\n",
    "        outcome1 = np.random.choice([0,1],1,p=[p0,1-p0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .56\n",
    "states_wasted = 10**4\n",
    "\n",
    "def main():\n",
    "    for episode in range(states_wasted):\n",
    "        phase = np.random.choice([-1,1],1)[0]\n",
    "        beta1 = give_first_beta()\n",
    "        p0 = np.exp(-(beta1-(phase*np.cos(ats[0])*alpha))**2)\n",
    "        outcome1 = np.random.choice([0,1],1,p=[p0,1-p0])\n",
    "        new_state = [outcome1, beta1]\n",
    "        beta2 = give_second_beta(new_state)\n",
    "        p1 = np.exp(-(beta2-(phase*np.sin(ats[0])*alpha))**2\n",
    "        outcome2 = np.random.choice([0,1],1,p=[p1,1-p1])\n",
    "        new_state = [outcome1, outcome2, beta1, beta2]\n",
    "        guess = give_guess(new_state)\n",
    "        if guess == phase:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "        buffer.add_sample((beta1, outcome1, beta2, outcome2, guess, reward))\n",
    "        if episode > 3*batch_size:\n",
    "            learn()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
