{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial we'll show how to train a DDPG agent to learn optimal Kennedy receiver. This involve not only displacement optimization but also to learn a (trivial, yet demaning) guessing rule among the possible phases. We aim to clear the background so in the next tutorial we can consider complex displacements and thereby more phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "#### this is the outcome probability, given by the overlap <0|\\alpha - \\beta>|Â¨^{2}\n",
    "def Prob(alpha, beta, n):\n",
    "    p0 = np.exp(-(alpha-beta)**2)\n",
    "    if n == 0:\n",
    "        return p0\n",
    "    else:\n",
    "        return 1-p0\n",
    "\n",
    "### this is just p(R=1 | g, n; beta) = p((-1^{g} alpha | n)) = p(n|allpha) pr(alpha)(p(n))\n",
    "def qval(beta, n, guess):\n",
    "    #dolinar guessing rule (= max-likelihood for L=1, careful sign of \\beta)\n",
    "    alpha = 0.4\n",
    "    pn = np.sum([Prob(g*alpha, beta, n) for g in [-1,1]])\n",
    "    return Prob(guess*alpha, beta, n)/pn\n",
    "\n",
    "def ps_maxlik(beta):\n",
    "    #dolinar guessing rule (= max-likelihood for L=1, careful sign of \\beta)\n",
    "    alpha = 0.4\n",
    "    p=0\n",
    "    for n1 in [0,1]:\n",
    "       p+=Prob(np.sign(beta)*(-1)**(n1)*alpha, beta, n1)\n",
    "    return p/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we create the replay memory, in which we store the transitions with the corresponding rewards, and also we add some data to test how the agent is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_size=10**3):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.count = 0\n",
    "        self.betas = np.arange(-1.5,1.5,0.01)\n",
    "        self.buffer = deque()\n",
    "        self.create_test_datasets()\n",
    "        \n",
    "    def create_test_datasets(self):\n",
    "        dt_l0 = []\n",
    "        dt_l1 = []\n",
    "        \n",
    "        for k in self.betas:\n",
    "            dt_l0.append([k, ps_maxlik(k)])\n",
    "            for n in [0.,1.]:\n",
    "                for g in [-1.,1.]:\n",
    "                    dt_l1.append([k, n, g, qval(k,n,g)])\n",
    "        self.test_l0 = np.array(dt_l0)\n",
    "        self.test_l1 = np.array(dt_l1)\n",
    "        return\n",
    "    \n",
    "    def add(self, beta, outcome, guess, reward):\n",
    "        experience = (beta, outcome, guess, reward)\n",
    "        if self.count < self.buffer_size:\n",
    "            self.buffer.append(experience)\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.buffer.popleft()\n",
    "            self.buffer.append(experience)\n",
    "\n",
    "    def size(self):\n",
    "        return self.count\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = []\n",
    "        if self.count < batch_size:\n",
    "            batch = random.sample(self.buffer, self.count)\n",
    "        else:\n",
    "            batch = random.sample(self.buffer, int(batch_size))\n",
    "        beta_batch, outcome_batch, guess_batch, r_batch= list(map(np.array, list(zip(*batch))))\n",
    "        return np.array([beta_batch, outcome_batch, guess_batch, r_batch]).transpose()\n",
    "\n",
    "    def clear(self):\n",
    "        self.buffer.clear()\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the networks! notice we add some features that may be unimportant for some objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    #input_dim: 1 if layer=0, 3 if layer= 2, for the Kennedy receiver ##\n",
    "    def __init__(self, input_dim, valreg=0.01, seed_val=0.1):\n",
    "        super(Critic,self).__init__()\n",
    "\n",
    "        self.l1 = Dense(50, input_shape=(input_dim,),kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(50, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "        self.l3 = Dense(50, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l4 = Dense(50, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l5 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    def update_target_parameters(self,primary_net, tau=0.01):\n",
    "        #### only \n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(tau * prim_weights[i] + (1 - tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, input):\n",
    "        feat = tf.nn.relu(self.l1(input))\n",
    "#        feat = tf.nn.dropout(feat, rate=0.01)\n",
    " #       feat = tf.nn.relu(self.l2(feat))\n",
    "  #      feat = tf.nn.dropout(feat, rate=0.01)\n",
    "   #     feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.relu(self.l4(feat))\n",
    "        feat = tf.nn.sigmoid(self.l5(feat))\n",
    "        return feat\n",
    "\n",
    "    def calculate_greedy_from_batch(self, batch):\n",
    "        \"\"\" this function is only to intended for Q(n, beta, guess).\n",
    "        Assuming batch = np.array([[beta, n, guess], [beta1, n1, guess], ...])\n",
    "        \n",
    "        \"\"\"\n",
    "        a = batch.copy()\n",
    "        preds1 = self(a)\n",
    "        a[:,2] = -a[:,2]\n",
    "        preds2 = self(a)\n",
    "        both = tf.concat([preds1,preds2],1)\n",
    "        maxs = np.squeeze(tf.math.reduce_max(both,axis=1))\n",
    "        maxs = np.expand_dims(maxs, axis=1)\n",
    "        return maxs\n",
    "    \n",
    "    def give_favourite_guess(self, beta, outcome):\n",
    "        \"\"\"\"This funciton is only intended for Q(n, beta, guess)\"\"\"\n",
    "        h1a2 = np.array([[beta, outcome,-1.]])\n",
    "        pred_minus = self(h1a2)\n",
    "        h1a2[:,2] = 1.\n",
    "        pred_plus = self(h1a2)\n",
    "        both = tf.concat([pred_plus,pred_minus],1)\n",
    "        maxs = tf.argmax(both,axis=1)\n",
    "        guess = (-1)**maxs.numpy()[0]\n",
    "        return guess\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    \n",
    "    \n",
    "##### ACTOR CLASSS ####    \n",
    "class Actor(tf.keras.Model):\n",
    "    #input_dim: 1 if layer=0, 3 if layer= 2, for the Kennedy receiver ##\n",
    "    def __init__(self, input_dim=1, valreg=0.01, seed_val=0.1):\n",
    "        super(Actor,self).__init__()\n",
    "\n",
    "        self.l1 = Dense(50, input_shape=(input_dim,),kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(50, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "        self.l3 = Dense(50, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l4 = Dense(50, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        self.l5 = Dense(1, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val),\n",
    "    bias_initializer = tf.random_uniform_initializer(minval=-seed_val, maxval=seed_val))\n",
    "\n",
    "        \n",
    "    def update_target_parameters(self,primary_net, tau=0.01):\n",
    "        #### only \n",
    "        prim_weights = primary_net.get_weights()\n",
    "        targ_weights = self.get_weights()\n",
    "        weights = []\n",
    "        for i in tf.range(len(prim_weights)):\n",
    "            weights.append(tau * prim_weights[i] + (1 - tau) * targ_weights[i])\n",
    "        self.set_weights(weights)\n",
    "        return\n",
    "\n",
    "    def call(self, input):\n",
    "        feat = tf.nn.relu(self.l1(input))\n",
    "#        feat = tf.nn.dropout(feat, rate=0.01)\n",
    " #       feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.dropout(feat, rate=0.01)\n",
    "   #     feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.relu(self.l4(feat))\n",
    "        feat = tf.nn.tanh(self.l5(feat))\n",
    "        return feat\n",
    "\n",
    "    def calculate_greedy_from_batch(self, batch):\n",
    "        \"\"\" this function is only to intended for Q(n, beta, guess)\"\"\"\n",
    "        a = batch[1].copy()\n",
    "        preds1 = self(a)\n",
    "        a[:,2] = -a[:,2]\n",
    "        preds2 = self(a)\n",
    "        both = tf.concat([preds1,preds2],1)\n",
    "        maxs = np.squeeze(tf.math.reduce_max(both,axis=1))\n",
    "        maxs = np.expand_dims(maxs, axis=1)\n",
    "        return maxs\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are some functions for 1) compute the predictions and 2) optimization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_data(buffer,networks):\n",
    "    actor_q0, critic_q0, critic_guess, target_guess = networks\n",
    "    ### this is the test data for the guess network, defined in Dataset() classs\n",
    "    predstest = critic_guess(buffer.test_l1[:,[0,1,2]])\n",
    "    targets_1 = np.expand_dims(buffer.test_l1[:,3], axis=1)\n",
    "    loss_test_l1 = tf.keras.losses.MSE(targets_1, predstest)\n",
    "    loss_test_l1 = tf.reduce_mean(loss_test_l1)\n",
    "    test_loss_l1(loss_test_l1)\n",
    "    print(\"test loss!!!! l1!!!: \",loss_test_l1.numpy())\n",
    "    \n",
    "    ### this is the test data for the \\hat{Q}('beta) #####\n",
    "    preds_test_l0 = critic_q0(np.expand_dims(buffer.test_l0[:,0], axis=1))\n",
    "    loss_y0 = tf.keras.losses.MSE(np.expand_dims(buffer.test_l0[:,1], axis=1), preds_test_l0)\n",
    "    loss_y0 = tf.reduce_mean(loss_y0)\n",
    "    test_loss_l0(loss_y0)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def optimization_step(networks, optimizers, buffer, batch_size=500., tau=0.01, repetitions=1):\n",
    "    actor_q0, critic_q0, critic_guess, target_guess = networks\n",
    "    optimizer_critic_guess,  optimizer_actor_l0, optimizer_critic_l0 = optimizers\n",
    "    for thoughts in range(repetitions):\n",
    "        experiences = buffer.sample(batch_size)\n",
    "\n",
    "        ##### update the critic guess according to rewards obtained \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(critic_guess.trainable_variables)\n",
    "            preds_cguess = critic_guess(experiences[:,[0,1,2]])\n",
    "            labels_cguess = np.expand_dims(experiences[:,3],axis=1)\n",
    "            loss_prim_guess = tf.keras.losses.MSE(labels_cguess, preds_cguess)\n",
    "            loss_prim_guess = tf.reduce_mean(loss_prim_guess)\n",
    "            grads = tape.gradient(loss_prim_guess, critic_guess.trainable_variables)\n",
    "            optimizer_critic_guess.apply_gradients(zip(grads, critic_guess.trainable_variables))\n",
    "            train_loss_l1(loss_prim_guess)\n",
    "\n",
    "        ##### update the target guess ######\n",
    "        target_guess.update_target_parameters(critic_guess, tau=0.01) #check this value !\n",
    "\n",
    "        #### obtain the labels for the update of Q(\\beta)\n",
    "        labels_critic_l0 = target_guess.calculate_greedy_from_batch(experiences[:,[0,1,2]]) #greedy from target; this is the label for net_0!!\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(critic_q0.trainable_variables)\n",
    "            preds0 = critic_q0(np.expand_dims(experiences[:,0],axis=1))\n",
    "            loss_0 = tf.keras.losses.MSE(labels_critic_l0,preds0)\n",
    "            loss_0 = tf.reduce_mean(loss_0)\n",
    "            grads0 = tape.gradient(loss_0, critic_q0.trainable_variables)\n",
    "            optimizer_critic_l0.apply_gradients(zip(grads0, critic_q0.trainable_variables))\n",
    "        train_loss_l0(loss_0)\n",
    "\n",
    "        #### obtain the components for the chain for the update of \\pi( h_0 = nada!) = \\beta\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_q0(np.expand_dims(np.zeros(len(experiences)),axis=1))\n",
    "            tape.watch(actions)\n",
    "            qvals = critic_q0(actions)\n",
    "            dq_da = tape.gradient(qvals, actions)\n",
    "\n",
    "        ### update actor \\pi( h_0) = \\beta\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_q0(np.expand_dims(np.zeros(len(experiences)),axis=1))\n",
    "            da_dtheta = tape.gradient(actions, actor_q0.trainable_variables, output_gradients=-dq_da)\n",
    "            optimizer_actor_l0.apply_gradients(zip(da_dtheta, actor_q0.trainable_variables))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BigPlot(buffer, rt, pt, history_betas, history_betas_would_have_done, histo_preds, losses, directory):\n",
    "\n",
    "    plt.figure(figsize=(40,40), dpi=100)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    T=len(rt)\n",
    "    ax1=plt.subplot2grid((2,4),(0,0))\n",
    "    ax2=plt.subplot2grid((2,4),(1,0))\n",
    "    ax3=plt.subplot2grid((2,4),(0,1))\n",
    "    ax4=plt.subplot2grid((2,4),(1,1))\n",
    "    ax5=plt.subplot2grid((2,4),(0,2))\n",
    "    ax6=plt.subplot2grid((2,4),(1,2))\n",
    "    ax7=plt.subplot2grid((2,4),(0,3))\n",
    "    ax8=plt.subplot2grid((2,4),(1,3))\n",
    "\n",
    "    optimal = max([ps_maxlik(b) for b in buffer.betas])\n",
    "\n",
    "    ### ploting the \\Rt and \\Pt ###\n",
    "    ax1.plot(np.log10(np.arange(1,T+1)),rt, color=\"red\", linewidth=15, alpha=0.8, label=r'$R_t$')\n",
    "    ax1.plot(np.log10(np.arange(1,T+1)),optimal*np.ones(T), color=\"black\",  linewidth=15,alpha=0.5, label=\"optimal\")\n",
    "    ax1.plot(np.log10(np.arange(1,T+1)),pt, color=\"blue\", linewidth=8, alpha=0.3, label=r'$P_t (fluctuates!)$')\n",
    "\n",
    "    ## ploting the histogram for betas ##\n",
    "    optimal_beta = buffer.betas[np.where(ps_maxlik(buffer.betas) == max(ps_maxlik(buffer.betas)))[0][0]]\n",
    "    ax2.hist(history_betas,bins=100, facecolor='r', alpha=0.6, edgecolor='blue', label=\"done\")\n",
    "    ax2.hist(history_betas_would_have_done,bins=100, facecolor='g', alpha=0.4, edgecolor='black', label=\"would have done\")\n",
    "    ax2.text(optimal_beta, 0, \"*\", size=30)\n",
    "    ax2.text(-optimal_beta, 0, \"*\", size=30)\n",
    "\n",
    "    ## ploting the history of betas ##\n",
    "    ax3.plot(np.arange(1, len(history_betas)+1),history_betas, color=\"red\", linewidth=15, alpha=0.8, label=\"done\")\n",
    "    ax3.plot(np.arange(1, len(history_betas)+1),history_betas_would_have_done, color=\"green\", linewidth=15, alpha=0.8, label=\"would have done\")\n",
    "    ax3.plot(np.arange(1, len(history_betas)+1),np.ones(len(history_betas))*optimal_beta, color=\"black\", linewidth=15, alpha=0.8, label=\"optimal-beta\")\n",
    "    ax3.plot(np.arange(1, len(history_betas)+1),-np.ones(len(history_betas))*optimal_beta, color=\"black\", linewidth=15, alpha=0.8)#, label=\"optimal-beta\")\n",
    "\n",
    "\n",
    "    #### in here i plot the loss for the first Q(0), the test and the train. Notice they have different scale! I use different colors!\n",
    "    c=0\n",
    "    lab = [\"train\",\"test\"]\n",
    "    colors = [\"tab:red\",\"tab:blue\"]\n",
    "    for loss in losses[0]:\n",
    "        color = colors[c]\n",
    "        ax4.plot(np.arange(1,len(loss)+1),loss,'--',alpha=0.85,c=colors[c], linewidth=5, label=\"Preds Q(\\beta) - \"+lab[c])#, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax4.scatter(np.arange(1,len(loss)+1),loss,s=150,alpha=0.85,c=colors[c], linewidth=5,label=\"Preds Q(\\beta) - \"+lab[c])#, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax4.set_xlabel(\"epoch\", size=20)\n",
    "        ax4.set_ylabel(\"Loss Q(\\beta_1)\",size=20, color =colors[c])\n",
    "        ax4.tick_params(axis='y', labelcolor=colors[c])\n",
    "        ax4 = ax4.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        c+=1\n",
    "\n",
    "    #### in here i plot the loss for the first Q(\\beta, n, guess ), the test and the train. Notice they have different scale! I use different colors!\n",
    "    c=0\n",
    "    for loss in losses[1]:\n",
    "        ax5.plot(np.arange(1,len(loss)+1),loss,'--',alpha=0.85,c=colors[c], linewidth=5, label=\"Preds Q(n, \\beta, guess) - \"+lab[c])#, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax5.scatter(np.arange(1,len(loss)+1),loss,s=150,alpha=0.85,c=colors[c], linewidth=5, label=\"Preds Q(n, \\beta, guess) - \"+lab[c])#, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax5.set_xlabel(\"epoch\", size=20)\n",
    "        ax5.set_ylabel(\"Loss Q(\\beta_1, n, guess)\",size=20, color =colors[c])\n",
    "        ax5.tick_params(axis='y', size=20, labelcolor=colors[c])\n",
    "        ax5 = ax5.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        c+=1\n",
    "        #plt.tight_layout()  # otherwise the right y-label is slightly clipped    \n",
    "\n",
    "\n",
    "    betas_train = buffer.betas\n",
    "    for predictions in histo_preds[\"net_1\"].values():\n",
    "        ax7.plot(betas_train,predictions[\"values\"][\"0\"],alpha=0.25, linewidth=5)#, label=\"epoch: \"+str(predictions[\"epoch_number\"])) #, label=r'$\\hat{Q}$'+\"(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax7.plot(betas_train,predictions[\"values\"][\"1\"],alpha=0.25, linewidth=5)#, label=\"epoch: \"+str(predictions[\"epoch_number\"]))#,label=r'$\\hat{Q}$'+\"(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "        ax8.plot(betas_train,predictions[\"values\"][\"2\"] ,alpha=0.25,  linewidth=5)#, label=\"epoch: \"+str(predictions[\"epoch_number\"]))#label=r'$\\hat{Q}$'+\"(n1=1,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "        ax8.plot(betas_train,predictions[\"values\"][\"3\"] ,alpha=0.25,  linewidth=5)#, label=\"epoch: \"+str(predictions[\"epoch_number\"]))#,label=r'$\\hat{Q}$'+\"(n1=1,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "    #Now we take the last and plot it in bold!\n",
    "    ax7.plot(betas_train,predictions[\"values\"][\"0\"],alpha=0.85, c=\"black\",linewidth=8)#), label=\"epoch: \"+str(predictions[\"epoch_number\"])) #, label=r'$\\hat{Q}$'+\"(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax7.plot(betas_train,predictions[\"values\"][\"1\"],alpha=0.85, c=\"purple\", linewidth=8)#, label=\"epoch: \"+str(predictions[\"epoch_number\"]))#,label=r'$\\hat{Q}$'+\"(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "    ax7.scatter(betas_train,predictions[\"values\"][\"0\"],alpha=0.85, c=\"black\",s=150)\n",
    "    ax7.scatter(betas_train,predictions[\"values\"][\"1\"],alpha=0.85, c=\"purple\",s=150)\n",
    "\n",
    "    ax8.plot(betas_train,predictions[\"values\"][\"2\"] ,alpha=0.85, c=\"black\", linewidth=8)#, label=\"epoch: \"+str(predictions[\"epoch_number\"]))#label=r'$\\hat{Q}$'+\"(n1=1,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax8.plot(betas_train,predictions[\"values\"][\"3\"] ,alpha=0.85,  c=\"purple\",linewidth=8)#, label=\"epoch: \"+str(predictions[\"epoch_number\"]))#,label=r'$\\hat{Q}$'+\"(n1=1,\"+r'$\\beta$'+\"; g=1)\")\n",
    "    ax8.scatter(betas_train,predictions[\"values\"][\"2\"],alpha=0.85, c=\"black\",s=150)\n",
    "    ax8.scatter(betas_train,predictions[\"values\"][\"3\"],alpha=0.85, c=\"purple\",s=150)\n",
    "\n",
    "\n",
    "        ### we do the same for ax3:\n",
    "\n",
    "    for predictions in histo_preds[\"net_0\"].values():\n",
    "        ax6.plot(betas_train,predictions[\"values\"],alpha=0.15, linewidth=5)#, label=\"epoch: \"+str(predictions[\"epoch_number\"])) #, label=r'$\\hat{Q}$'+\"(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "\n",
    "    #The last one black and bigger!\n",
    "    ax6.plot(betas_train,predictions[\"values\"],alpha=0.85,c=\"black\", linewidth=5)#, label=\"epoch: \"+str(predictions[\"epoch_number\"])) #, label=r'$\\hat{Q}$'+\"(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "\n",
    "\n",
    "    ##### here we plot the true values (that we want to learn!!!) ###\n",
    "    ax7.plot(buffer.betas,[qval(b, 0, -1) for b in buffer.betas],'--',alpha=0.85,c=\"red\", linewidth=8, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax7.plot(buffer.betas,[qval(b, 0, 1) for b in buffer.betas],'--',alpha=0.85,c=\"blue\",  linewidth=8,label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "    ax8.plot(buffer.betas,[qval(b, 1, -1) for b in buffer.betas],'--',alpha=0.85,c=\"red\",  linewidth=8,label=\"Q(n1=1,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax8.plot(buffer.betas,[qval(b, 1, 1) for b in buffer.betas],'--',alpha=0.85,c=\"blue\",  linewidth=8,label=\"Q(n1=1,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "    ax6.plot(buffer.betas,[ps_maxlik(b) for b in buffer.betas],'--',alpha=0.85,c=\"red\", linewidth=8)\n",
    "    ax6.set_ylabel(r'$P_s\\; ( \\beta )$', size=20)\n",
    "    ##### here we plot the true values (that we want to learn!!!) ###\n",
    "\n",
    "\n",
    "\n",
    "    for ax in [ax6, ax7, ax8]:\n",
    "        ax.set_xlabel(r'$\\beta$', size=20)\n",
    "\n",
    "    for ax in [ax1, ax2, ax3,ax4,ax5,ax6, ax7, ax8]:\n",
    "        ax.legend(prop={\"size\":30})\n",
    "\n",
    "    plt.savefig(directory+\"/big_plot.png\")\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inside_buffer(buffer, directory):\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax1 =  plt.subplot2grid((1,2),(0,0))\n",
    "    ax2 =  plt.subplot2grid((1,2),(0,1))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    histo = {}\n",
    "    number = {}\n",
    "\n",
    "    data_collected = np.asarray(buffer.buffer)\n",
    "    for k in data_collected[:,0]:\n",
    "        for g in [-1.,1.]:\n",
    "            for outcome in [0.,1.]:\n",
    "\n",
    "                histo[str(np.round(k,2))+\"n\"+str(outcome)+\"g\"+str(g)] = 0\n",
    "                number[str(np.round(k,2))+\"n\"+str(outcome)+\"g\"+str(g)] = 1\n",
    "\n",
    "    for dato in data_collected:\n",
    "        histo[str(np.round(dato[0],2))+\"n\"+str(dato[1])+\"g\"+str(dato[2])] += dato[3]\n",
    "        number[str(np.round(dato[0],2))+\"n\"+str(dato[1])+\"g\"+str(dato[2])] += 1\n",
    "\n",
    "    for k in data_collected[:,0]:\n",
    "        for g in [-1.,1.]:\n",
    "            for outcome in [0.,1.]:\n",
    "                histo[str(np.round(k,2))+\"n\"+str(outcome)+\"g\"+str(g)] /=number[str(np.round(k,2))+\"n\"+str(outcome)+\"g\"+str(g)] \n",
    "\n",
    "\n",
    "\n",
    "    betas  = [np.round(b,2) for b in data_collected[:,0]]\n",
    "    ax1.plot(betas,[histo[str(np.round(b,2))+\"n0.0g-1.0\"] for b in data_collected[:,0]],alpha=0.5,c=\"red\", linewidth=5, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax1.plot(betas,[histo[str(np.round(b,2))+\"n0.0g1.0\"] for b in data_collected[:,0]],alpha=0.5,c=\"blue\", linewidth=5, label=\"Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "\n",
    "    ax2.plot(betas,[histo[str(np.round(b,2))+\"n1.0g-1.0\"] for b in data_collected[:,0]],alpha=0.5,c=\"red\", linewidth=5, label=\"Q(n1=1,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax2.plot(betas,[histo[str(np.round(b,2))+\"n1.0g1.0\"] for b in data_collected[:,0]],alpha=0.5,c=\"blue\", linewidth=5, label=\"Q(n1=1,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "\n",
    "    betas = np.arange(-1.5,1.5,.01)\n",
    "    ax1.plot(betas,[qval(b, 0, -1) for b in betas],'--',alpha=0.5,c=\"red\", linewidth=5, label=\"True Q(n1=0,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax1.plot(betas,[qval(b, 0, 1) for b in betas],'--',alpha=0.5,c=\"blue\",  linewidth=5,label=\"True Q(n1=0,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "    ax2.plot(betas,[qval(b, 1, -1) for b in betas],'--',alpha=0.5,c=\"red\",  linewidth=5,label=\"True Q(n1=1,\"+r'$\\beta$'+\"; g=-1)\")\n",
    "    ax2.plot(betas,[qval(b, 1, 1) for b in betas],'--',alpha=0.5,c=\"blue\",  linewidth=5,label=\"True Q(n1=1,\"+r'$\\beta$'+\"; g=1)\")\n",
    "\n",
    "\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_xlabel(r'$\\beta$', size=20)\n",
    "        ax.legend(prop={\"size\":15})\n",
    "\n",
    "    plt.savefig(directory+\"/inside_buffer.png\")\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### if you want to delete the folder with data generated by tensorflow (and the program), you can do it with this command .... !rm -rf \"logs/ddpg_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpgKennedy(total_episodes = 10**3,buffer_size=500, batch_size=64, ep_guess=0.01, noise_displacement=0.5,lr_actor=0.01, lr_critic=0.001, tau=0.005, repetitions=1):\n",
    "\n",
    "    amplitude = 0.4\n",
    "    buffer = ReplayBuffer(buffer_size=buffer_size)\n",
    "    \n",
    "    critic_q0 = Critic(input_dim=1)\n",
    "    actor_q0 = Actor(input_dim=1)\n",
    "    critic_guess = Critic(input_dim=3)\n",
    "    target_guess = Critic(input_dim=3)\n",
    "\n",
    "    critic_q0(np.array([[0.],[1.]])) #initialize the network 0, arbitrary inputs.\n",
    "    actor_q0(np.array([[0.],[1.]])) #initialize the network 0, arbitrary inputs.\n",
    "    critic_guess(np.array([[0.,1.,1.]]))\n",
    "    target_guess(np.array([[0.,1.,1.]]))\n",
    "    #\n",
    "    optimizer_critic_guess = tf.keras.optimizers.Adam(lr=lr_critic)\n",
    "    optimizer_actor_l0 = tf.keras.optimizers.Adam(lr=lr_actor)\n",
    "    optimizer_critic_l0 = tf.keras.optimizers.Adam(lr=lr_actor)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    rt = []\n",
    "    pt = [] \n",
    "\n",
    "    global train_loss_l0, train_loss_l1, test_loss_l0, test_loss_l1 #define this global so i use them in a function defined above... optimizatin step and testing()\n",
    "    train_loss_l0 = tf.keras.metrics.Mean('train_loss_l0', dtype=tf.float32)\n",
    "    test_loss_l0 = tf.keras.metrics.Mean('test_loss_l0', dtype=tf.float32)\n",
    "    train_loss_l1 = tf.keras.metrics.Mean('train_loss_l1', dtype=tf.float32)\n",
    "    test_loss_l1 = tf.keras.metrics.Mean('test_loss_l1', dtype=tf.float32)\n",
    "\n",
    "\n",
    "    current_run_and_time = \"time-{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "    directory = 'logs/ddpg_results/' + current_run_and_time \n",
    "    train_log_dir_0 = 'logs/ddpg_results/' + current_run_and_time + '/train_l0'\n",
    "    test_log_dir_0 = 'logs/ddpg_results/' +  current_run_and_time + '/test_l0'\n",
    "    train_log_dir_1 = 'logs/ddpg_results/' +  current_run_and_time + '/train_l1'\n",
    "    test_log_dir_1 = 'logs/ddpg_results/' +  current_run_and_time + '/test_l1'\n",
    "    train_summary_writer_0 = tf.summary.create_file_writer(train_log_dir_0)\n",
    "    train_summary_writer_1 = tf.summary.create_file_writer(train_log_dir_1)\n",
    "    test_summary_writer_0 = tf.summary.create_file_writer(test_log_dir_0)\n",
    "    test_summary_writer_1 = tf.summary.create_file_writer(test_log_dir_1)\n",
    "\n",
    "    info_optimizers = \"optimizer_critic_guess: {} \\nOptimizer_actor_l0: {}\\nOptimizer_critic_l0: {}\\n\".format(optimizer_critic_guess.get_config(), optimizer_actor_l0.get_config(), optimizer_critic_l0)\n",
    "    infor_buffer = \"Buffer_size: {}\\n Batch_size for sampling: {}\\n\".format(buffer.buffer_size, batch_size)\n",
    "    info_epsilons= \"epsilon-guess: {}\\nepsilon_displacement_noise: {}\".format(ep_guess,noise_displacement)\n",
    "    \n",
    "    data = \"tau: {}, repetitions per optimization step (would be like epochs): {}\".format(tau,repetitions) + \"\\n \\n**** optimizers ***\\n\"+info_optimizers+\"\\n\\n\\n*** BUFFER ***\\n\"+infor_buffer+\"\\n\\n\\n *** NOISE PARAMETERS *** \\n\"+info_epsilons\n",
    "    with open(directory+\"/info.txt\", 'w') as f:\n",
    "        f.write(data)\n",
    "        f.close()    \n",
    "    \n",
    "    print(\"Beggining to train! \\n \\n\")\n",
    "    print(data)\n",
    "    print(\"starting time: {}\".format(datetime.now().strftime(\"%Y%m%d-%H%M\")))\n",
    "    print(\"saving results in \" + str(directory))\n",
    "    avg_train_l0 = []\n",
    "    avg_train_l1 = []\n",
    "    avg_test_l0 = []\n",
    "    avg_test_l1 = []\n",
    "\n",
    "    history_betas = [] #to put in histogram\n",
    "    history_betas_would_have_done=[] #to put in histogram\n",
    "    histo_preds = {\"net_0\":{}, \"net_1\":{}} #here i save the predictions to plot in a \"straightforward way\"\n",
    "\n",
    "    #######\n",
    "    for episode in tqdm(range(total_episodes)):\n",
    "\n",
    "        alice_phase = np.random.choice([-1.,1.],1)[0]\n",
    "        beta_would_do = actor_q0(np.array([[0.]])).numpy()[0][0]\n",
    "        beta =  beta_would_do + np.random.uniform(-noise_displacement, noise_displacement)\n",
    "        proboutcome = Prob(alice_phase*amplitude,beta,0)\n",
    "        outcome = np.random.choice([0.,1.],1,p=[proboutcome, 1-proboutcome])[0]\n",
    "\n",
    "        history_betas.append(beta)\n",
    "        history_betas_would_have_done.append(beta_would_do)\n",
    "        #epsilon-greedy choice of the guessing! Do you imagine other way to do this? How would you apply UCB ? discretize?\n",
    "        if np.random.random()< ep_guess:\n",
    "            guess = np.random.choice([-1.,1.],1)[0]\n",
    "        else:\n",
    "            guess = critic_guess.give_favourite_guess(beta, outcome) \n",
    "        if guess == alice_phase:\n",
    "            reward = 1.\n",
    "        else:\n",
    "            reward = 0.\n",
    "        buffer.add(beta, outcome, guess, reward)\n",
    "\n",
    "\n",
    "        ### optimization step and testing the generalization performance ! ####\n",
    "        optimization_step(networks=[actor_q0, critic_q0, critic_guess, target_guess], \n",
    "                          optimizers = [optimizer_critic_guess,  optimizer_actor_l0, optimizer_critic_l0 ],buffer=buffer,\n",
    "                          batch_size=batch_size,repetitions=repetitions)\n",
    "        testing_data(buffer, networks=[actor_q0, critic_q0, critic_guess, target_guess])\n",
    "\n",
    "        ### i append the losses to plot them later ###\n",
    "        avg_train_l0.append(train_loss_l0.result().numpy())\n",
    "        avg_train_l1.append(train_loss_l1.result().numpy())\n",
    "        avg_test_l0.append(test_loss_l0.result().numpy())\n",
    "        avg_test_l1.append(test_loss_l1.result().numpy())\n",
    "\n",
    "\n",
    "        ### appending the reward to calculate cumulative! ###\n",
    "        rt.append(reward)\n",
    "\n",
    "        ### calculate success probability if the agent went greedy ###\n",
    "        p=0\n",
    "        for outcome in [0.,1.]:\n",
    "            p+=Prob(critic_guess.give_favourite_guess(beta_would_do, outcome)*amplitude, beta_would_do,outcome)\n",
    "        p/=2\n",
    "        pt.append(p)\n",
    "        \n",
    "\n",
    "        \n",
    "        with train_summary_writer_0.as_default():\n",
    "            tf.summary.scalar('loss', train_loss_l0.result(), step=episode)\n",
    "        with test_summary_writer_0.as_default():\n",
    "            tf.summary.scalar('loss', test_loss_l0.result(), step=episode)\n",
    "        with train_summary_writer_1.as_default():\n",
    "            tf.summary.scalar('loss', train_loss_l1.result(), step=episode)\n",
    "        with test_summary_writer_1.as_default():\n",
    "            tf.summary.scalar('loss', test_loss_l1.result(), step=episode)\n",
    "\n",
    "        if episode%(total_episodes/10) == 0: #this is for showing 10 results in total.\n",
    "\n",
    "            template = 'Episode {}, \\Rt: {}, \\Pt: {}, Train loss_l1: {}, Test loss_l1: {}, Train Loss_l0: {}, Test Loss_l0: {}'\n",
    "            print(template.format(episode+1,\n",
    "                                np.sum(rt)/(episode+1),\n",
    "                                  pt[-1],\n",
    "                                 np.round(train_loss_l1.result().numpy(),5), \n",
    "                                 test_loss_l1.result().numpy(), \n",
    "                                 np.round(train_loss_l0.result().numpy(),15),\n",
    "                                 np.round(test_loss_l0.result().numpy(),5))\n",
    "                  )\n",
    "\n",
    "            for nett in [\"net_0\",\"net_1\"]: #net_0 will be critic_q0, net_1 will be critic_qguess\n",
    "\n",
    "                histo_preds[nett][str(episode)] ={}\n",
    "                histo_preds[nett][str(episode)][\"episode\"] = episode\n",
    "                histo_preds[nett][str(episode)][\"values\"] = {}\n",
    "\n",
    "                histo_preds[\"net_0\"][str(episode)][\"values\"] = np.squeeze(critic_q0(np.expand_dims(buffer.betas,axis=1)))\n",
    "\n",
    "            index=0\n",
    "            for n1 in [0.,1.]:\n",
    "                for guess in [-1.,1.]:\n",
    "                    foo =np.array([[b,n1,guess] for b in buffer.betas]) #betas_train defined as global in create_dataset_l2()\n",
    "                    histo_preds[\"net_1\"][str(episode)][\"values\"][str(index)] = np.squeeze(critic_guess(foo))\n",
    "                    index+=1\n",
    "\n",
    "\n",
    "    rt = [np.sum(rt[:k]) for k in range(len(rt))]\n",
    "    rt = rt/np.arange(1,len(rt)+1)\n",
    "    losses = [[avg_train_l0, avg_test_l0], [ avg_train_l1, avg_test_l1]]\n",
    "    BigPlot(buffer,rt, pt, history_betas, history_betas_would_have_done, histo_preds, losses, directory)\n",
    "    plot_inside_buffer(buffer, directory)\n",
    "    return #rt, pt, history_betas, history_betas_would_have_done, histo_preds, losses, name_directory-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beggining to train! \n",
      " \n",
      "\n",
      "tau: 0.001, repetitions per optimization step (would be like epochs): 1\n",
      " \n",
      "**** optimizers ***\n",
      "optimizer_critic_guess: {'name': 'Adam', 'learning_rate': 0.0001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False} \n",
      "Optimizer_actor_l0: {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
      "Optimizer_critic_l0: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fc90d1dbb38>\n",
      "\n",
      "\n",
      "\n",
      "*** BUFFER ***\n",
      "Buffer_size: 100000\n",
      " Batch_size for sampling: 500\n",
      "\n",
      "\n",
      "\n",
      " *** NOISE PARAMETERS *** \n",
      "epsilon-guess: 0.01\n",
      "epsilon_displacement_noise: 0.1\n",
      "starting time: 20200406-1758\n",
      "saving results in logs/ddpg_results/time-20200406-1758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:67: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2060da315ca34dee93f5d25087a7b16c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss!!!! l1!!!:  0.09226625959589313\n",
      "[0.09226626]\n",
      "Episode 1, \\Rt: 1.0, \\Pt: 0.5, Train loss_l1: 0.2748599946498871, Test loss_l1: 0.0922662615776062, Train Loss_l0: 0.0017411451553925872, Test Loss_l0: 0.058079998940229416\n",
      "test loss!!!! l1!!!:  0.09226148452127304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:65: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09226626, 0.09226388]\n",
      "test loss!!!! l1!!!:  0.09225898237974116\n",
      "[0.09226626, 0.09226388, 0.092262246]\n",
      "test loss!!!! l1!!!:  0.09225674718090728\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875]\n",
      "test loss!!!! l1!!!:  0.09225413228502305\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526]\n",
      "test loss!!!! l1!!!:  0.09225089479350025\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809]\n",
      "test loss!!!! l1!!!:  0.09224759449046362\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659]\n",
      "test loss!!!! l1!!!:  0.09224410923342456\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026]\n",
      "test loss!!!! l1!!!:  0.0922406751630975\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343]\n",
      "test loss!!!! l1!!!:  0.09223755926842642\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185]\n",
      "test loss!!!! l1!!!:  0.0922348816744176\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503]\n",
      "Episode 11, \\Rt: 0.45454545454545453, \\Pt: 0.5, Train loss_l1: 0.2540999948978424, Test loss_l1: 0.09225030243396759, Train Loss_l0: 0.0011593681992962956, Test Loss_l0: 0.05573999881744385\n",
      "test loss!!!! l1!!!:  0.09223274238291021\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835]\n",
      "test loss!!!! l1!!!:  0.09223084155433002\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745]\n",
      "test loss!!!! l1!!!:  0.09222897565110177\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613]\n",
      "test loss!!!! l1!!!:  0.09222688550090283\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485]\n",
      "test loss!!!! l1!!!:  0.0922248071558047\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436]\n",
      "test loss!!!! l1!!!:  0.09222293275433828\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238]\n",
      "test loss!!!! l1!!!:  0.09222139900644026\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121]\n",
      "test loss!!!! l1!!!:  0.0922202772500171\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012]\n",
      "test loss!!!! l1!!!:  0.09221936869021505\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074]\n",
      "test loss!!!! l1!!!:  0.09221850110680092\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381]\n",
      "Episode 21, \\Rt: 0.47619047619047616, \\Pt: 0.5, Train loss_l1: 0.2517000138759613, Test loss_l1: 0.09223809838294983, Train Loss_l0: 0.0007654371438547969, Test Loss_l0: 0.05358000099658966\n",
      "test loss!!!! l1!!!:  0.09221753915611375\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716]\n",
      "test loss!!!! l1!!!:  0.09221663211198028\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627]\n",
      "test loss!!!! l1!!!:  0.09221590918399326\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542]\n",
      "test loss!!!! l1!!!:  0.09221515342128438\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461]\n",
      "test loss!!!! l1!!!:  0.09221423223222298\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383]\n",
      "test loss!!!! l1!!!:  0.0922130910716565\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307]\n",
      "test loss!!!! l1!!!:  0.09221166702876436\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323]\n",
      "test loss!!!! l1!!!:  0.09221008481359637\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534]\n",
      "test loss!!!! l1!!!:  0.09220825048964829\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076]\n",
      "test loss!!!! l1!!!:  0.09220610021178481\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955]\n",
      "Episode 31, \\Rt: 0.5483870967741935, \\Pt: 0.5, Train loss_l1: 0.2514300048351288, Test loss_l1: 0.09222995489835739, Train Loss_l0: 0.0005285366787575185, Test Loss_l0: 0.051660001277923584\n",
      "test loss!!!! l1!!!:  0.09220379036282621\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss!!!! l1!!!:  0.09220124720096047\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829]\n",
      "test loss!!!! l1!!!:  0.09219811476130012\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741]\n",
      "test loss!!!! l1!!!:  0.09219453896056916\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647]\n",
      "test loss!!!! l1!!!:  0.09219068654621888\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548]\n",
      "test loss!!!! l1!!!:  0.09218652535387796\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443]\n",
      "test loss!!!! l1!!!:  0.09218203308055459\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331]\n",
      "test loss!!!! l1!!!:  0.09217737919485118\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213]\n",
      "test loss!!!! l1!!!:  0.09217284443189158\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895]\n",
      "test loss!!!! l1!!!:  0.09216860717942939\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962]\n",
      "Episode 41, \\Rt: 0.5365853658536586, \\Pt: 0.2935265936420452, Train loss_l1: 0.2518399953842163, Test loss_l1: 0.09221962094306946, Train Loss_l0: 0.0004058263439219445, Test Loss_l0: 0.0502300001680851\n",
      "test loss!!!! l1!!!:  0.09216440399642956\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831]\n",
      "test loss!!!! l1!!!:  0.0921600232124382\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695]\n",
      "test loss!!!! l1!!!:  0.0921556555489439\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556]\n",
      "test loss!!!! l1!!!:  0.09215143224575802\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414]\n",
      "test loss!!!! l1!!!:  0.09214721689387365\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684]\n",
      "test loss!!!! l1!!!:  0.09214300584469234\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121]\n",
      "test loss!!!! l1!!!:  0.09213885282457823\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss!!!! l1!!!:  0.0921346034639958\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816]\n",
      "test loss!!!! l1!!!:  0.09213047304286702\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661]\n",
      "test loss!!!! l1!!!:  0.09212650522725599\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504]\n",
      "Episode 51, \\Rt: 0.5098039215686274, \\Pt: 0.5, Train loss_l1: 0.2518799901008606, Test loss_l1: 0.09220504015684128, Train Loss_l0: 0.000336490455083549, Test Loss_l0: 0.049479998648166656\n",
      "test loss!!!! l1!!!:  0.09212250901365455\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345]\n",
      "test loss!!!! l1!!!:  0.09211857352507626\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185]\n",
      "test loss!!!! l1!!!:  0.09211461634048497\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235]\n",
      "test loss!!!! l1!!!:  0.09211071315389574\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986]\n",
      "test loss!!!! l1!!!:  0.09210699653036364\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964]\n",
      "test loss!!!! l1!!!:  0.09210354076441356\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325]\n",
      "test loss!!!! l1!!!:  0.09210022890421446\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685]\n",
      "test loss!!!! l1!!!:  0.0920971163271572\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054]\n",
      "test loss!!!! l1!!!:  0.09209424752359752\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042]\n",
      "test loss!!!! l1!!!:  0.09209163979655928\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042, 0.092188805]\n",
      "Episode 61, \\Rt: 0.47540983606557374, \\Pt: 0.5, Train loss_l1: 0.2516399919986725, Test loss_l1: 0.09218880534172058, Train Loss_l0: 0.000286665657768026, Test Loss_l0: 0.04927999898791313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss!!!! l1!!!:  0.0920893233979288\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042, 0.092188805, 0.092187196]\n",
      "test loss!!!! l1!!!:  0.09208718485421716\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042, 0.092188805, 0.092187196, 0.09218561]\n",
      "test loss!!!! l1!!!:  0.09208528327380491\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042, 0.092188805, 0.092187196, 0.09218561, 0.092184044]\n",
      "test loss!!!! l1!!!:  0.09208351393189694\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042, 0.092188805, 0.092187196, 0.09218561, 0.092184044, 0.092182495]\n",
      "test loss!!!! l1!!!:  0.09208179327065882\n",
      "[0.09226626, 0.09226388, 0.092262246, 0.092260875, 0.092259526, 0.09225809, 0.09225659, 0.092255026, 0.09225343, 0.09225185, 0.0922503, 0.092248835, 0.09224745, 0.09224613, 0.09224485, 0.0922436, 0.09224238, 0.09224121, 0.09224012, 0.092239074, 0.0922381, 0.09223716, 0.09223627, 0.09223542, 0.09223461, 0.09223383, 0.09223307, 0.0922323, 0.092231534, 0.09223076, 0.092229955, 0.09222914, 0.09222829, 0.09222741, 0.09222647, 0.09222548, 0.09222443, 0.09222331, 0.09222213, 0.092220895, 0.09221962, 0.09221831, 0.09221695, 0.09221556, 0.09221414, 0.092212684, 0.09221121, 0.0922097, 0.09220816, 0.09220661, 0.09220504, 0.09220345, 0.09220185, 0.092200235, 0.0921986, 0.092196964, 0.092195325, 0.092193685, 0.092192054, 0.09219042, 0.092188805, 0.092187196, 0.09218561, 0.092184044, 0.092182495, 0.092180975]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-ca8a0d203b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddpgKennedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_displacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_actor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-2c467ff9e59c>\u001b[0m in \u001b[0;36mddpgKennedy\u001b[0;34m(total_episodes, buffer_size, batch_size, ep_guess, noise_displacement, lr_actor, lr_critic, tau, repetitions)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0malice_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mbeta_would_do\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_q0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mbeta_would_do\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnoise_displacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_displacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mproboutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malice_phase\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-aa1f233eeca9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;31m#      feat = tf.nn.dropout(feat, rate=0.01)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m    \u001b[0;31m#     feat = tf.nn.relu(self.l3(feat))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cooper-cooper/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5604\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5605\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5606\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5607\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5608\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddpgKennedy(total_episodes=10**2, noise_displacement=0.1, tau=0.001, buffer_size=10**5, batch_size=500, lr_critic=0.0001, lr_actor=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
