{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Double DQN with proioritized memory in Tensorflow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from collections import deque, OrderedDict\n",
    "from ipypb import track\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    try:\n",
    "        gpu = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as error:\n",
    "        print('This config has already been invoked. Error message:')\n",
    "        print(error)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MsPacman-v0')\n",
    "actions_n = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, actions_n):\n",
    "        super(QNet, self).__init__()\n",
    "        kinit = tf.keras.initializers.VarianceScaling()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (8, 8), 4, 'same', kernel_initializer=kinit)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (4, 4), 2, 'same', kernel_initializer=kinit)\n",
    "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), 1, 'same', kernel_initializer=kinit)\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(256, kernel_initializer=kinit)\n",
    "        self.dense2 = tf.keras.layers.Dense(actions_n, kernel_initializer=kinit)\n",
    "        \n",
    "    def call(self, observation):\n",
    "        x = self.conv1(observation)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.0025)\n",
    "mse = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implement probability here\n",
    "class Memory:\n",
    "\n",
    "    def __init__(self, _max=10, batch_size=2, epsilon=1e-4, alpha=0.7):\n",
    "        self._max = _max\n",
    "        self.td_errors = [0 for _ in range(_max)]\n",
    "        self.memories = [0 for _ in range(_max)]\n",
    "        self.batch_size = batch_size\n",
    "        self.epislon = epsilon\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add_memory(self, td_error, memory):\n",
    "        if self.td_errors[0] < td_error:\n",
    "            self.td_errors[0] = td_error\n",
    "            self.memories[0] = memory\n",
    "            self.__sort()\n",
    "\n",
    "    def update_memories(self, td_errors):\n",
    "        self.td_errors[-self.batch_size:] = td_errors\n",
    "        self.__sort()\n",
    "\n",
    "    def get_memories(self):\n",
    "        perm = np.random.permutation(self._max)[:self.batch_size]\n",
    "        mem = np.array(self.memories)[perm]\n",
    "        obs = np.concatenate(mem[:,0])\n",
    "        obs_n = np.concatenate(mem[:,2])\n",
    "        return obs, mem[:,1], obs_n, mem[:,3], mem[:,4]\n",
    "    \n",
    "    def refresh(self):\n",
    "        self.td_errors = [0 for _ in range(self._max)]\n",
    "        self.memories = [0 for _ in range(self._max)]\n",
    "\n",
    "    def __sort(self):\n",
    "        zipped = sorted(zip(self.td_errors, self.memories), key=lambda x:x[0])\n",
    "        self.memories = [x for _, x in zipped]\n",
    "        self.td_errors = sorted(self.td_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.array([210, 164, 74]).mean()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = image[1:172:2,::2]\n",
    "    image = image.mean(axis=-1)\n",
    "    image[image==color] = 0\n",
    "    image = (image-128)/(128) \n",
    "    image = image[np.newaxis,:,:,np.newaxis]\n",
    "    return image\n",
    "\n",
    "def epsilon_greedy(action, step):\n",
    "    epsilon = max(EPS_MIN, EPS_MAX - (EPS_MAX-EPS_MIN) * step/EPS_STEPS)\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return np.random.randint(actions_n)\n",
    "    else:\n",
    "        return action\n",
    "    \n",
    "def pick_best_q(next_qs, best_next_a):\n",
    "    if isinstance(best_next_a, int):\n",
    "        return next_qs[:,best_next_a]\n",
    "    else:\n",
    "        best_next_a = best_next_a.astype('int32')\n",
    "        best_next_a_en = np.zeros((len(best_next_a), actions_n))\n",
    "        best_next_a_en[np.arange(len(best_next_a)), best_next_a] = 1\n",
    "        return (next_qs * best_next_a_en).sum(axis=-1)\n",
    "\n",
    "def sample_memories():\n",
    "    perm = np.random.permutation(len(exp_buffer))[:BATCH_SIZE]\n",
    "    mem = np.array(exp_buffer)[perm]\n",
    "    obs = np.concatenate(mem[:,0])\n",
    "    obs_n = np.concatenate(mem[:,2])\n",
    "    return obs, mem[:,1], obs_n, mem[:,3], mem[:,4]\n",
    "\n",
    "def play_pacman(render_jupyter=True):\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    if render_jupyter:\n",
    "        img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    while not done:\n",
    "        if render_jupyter:\n",
    "            img.set_data(env.render(mode='rgb_array'))\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            env.render()\n",
    "            time.sleep(0.020)\n",
    "        observation = preprocess(observation)\n",
    "        action = main_q(observation).numpy().argmax(axis=-1)\n",
    "        action = epsilon_greedy(action, np.inf)\n",
    "        observation, _, done, _ = env.step(action)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_network(obs, rewards, actions):\n",
    "    actions = tf.dtypes.cast(tf.one_hot(actions, actions_n), dtype='float64') #esto te da matriz len(actions_n)*deptphth     with tf.GradientTape() as tape:\n",
    "    all_qs = main_q(obs)\n",
    "    q_act = tf.squeeze(tf.reduce_sum(all_qs*actions, axis=-1, keepdims=True), axis=-1)\n",
    "    loss = mse(rewards, q_act)\n",
    "    gradients = tape.gradient(loss, main_q.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, main_q.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 800\n",
    "GAMMA = 0.97\n",
    "START_STEP = 1000\n",
    "COPY_STEP = 100\n",
    "TRAIN_STEP = 4\n",
    "\n",
    "MEM_LEN = 20000\n",
    "BATCH_SIZE = 48\n",
    "\n",
    "EPS_MIN = 0.05\n",
    "EPS_MAX = 1\n",
    "EPS_STEPS = 500000\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "exp_buffer = deque(maxlen=MEM_LEN)\n",
    "\n",
    "main_q = QNet(actions_n)\n",
    "target_q = QNet(actions_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__iter__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-25629ef1763c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPISODES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepisodic_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cooper-cooper/.local/lib/python3.6/site-packages/ipypb/progressbar.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarriage_moveup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# allow end='\\n' in print function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# also initializes display area for progressbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__iter__'"
     ]
    }
   ],
   "source": [
    "for _ in track(range(EPISODES)):\n",
    "\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    episodic_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        observation = preprocess(observation)\n",
    "        best_action = main_q(observation).numpy().argmax(axis=-1)\n",
    "        action = epsilon_greedy(best_action, global_step)\n",
    "\n",
    "        observation_n, reward, done, _ = env.step(action)\n",
    "        exp_buffer.append([observation, action, preprocess(observation_n), reward, done])\n",
    "\n",
    "        if (global_step % TRAIN_STEP) == 0 and (global_step > START_STEP):\n",
    "\n",
    "            t_observation, t_action, t_observation_n, t_reward, t_done = sample_memories()\n",
    "            \n",
    "            best_next_a = main_q(t_observation_n).numpy().argmax(axis=-1)\n",
    "            next_qs = target_q(t_observation_n).numpy()\n",
    "            best_next_q = pick_best_q(next_qs, best_next_a)\n",
    "            \n",
    "            rewards = np.expand_dims(t_reward + GAMMA*best_next_q*(1-t_done), axis=-1).astype('float32')\n",
    "            \n",
    "            train_network(t_observation, rewards, t_action.astype('int32'))\n",
    "            \n",
    "        if ((global_step+1) % COPY_STEP) == 0 and (global_step > START_STEP):\n",
    "            target_q = copy(main_q)\n",
    "        \n",
    "        observation = observation_n\n",
    "        episodic_reward += reward\n",
    "        global_step += 1\n",
    "    \n",
    "    print('Episodic reward: '+str(episodic_reward)+'. On global step: '+str(global_step)+'. Epsilon: '+str(max(EPS_MIN, EPS_MAX - (EPS_MAX-EPS_MIN) * global_step/EPS_STEPS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "play_pacman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
