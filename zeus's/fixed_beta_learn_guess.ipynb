{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "from misc import *\n",
    "from collections import deque\n",
    "from nets import Q2, Actor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Q2(tf.keras.Model):\n",
    "    def __init__(self, valreg=0.01):\n",
    "        super(Q2,self).__init__()\n",
    "\n",
    "        self.l1 = Dense(10, input_shape=(2,),kernel_initializer=tf.random_uniform_initializer(),\n",
    "        bias_initializer = tf.random_uniform_initializer(),\n",
    "        kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg))\n",
    "\n",
    "        self.l2 = Dense(10, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(),\n",
    "    bias_initializer = tf.random_uniform_initializer())\n",
    "        self.l3 = Dense(10, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(),\n",
    "    bias_initializer = tf.random_uniform_initializer())\n",
    "        \n",
    "        self.l4 = Dense(12, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(),\n",
    "    bias_initializer = tf.random_uniform_initializer())\n",
    "        \n",
    "        self.l5 = Dense(2, kernel_regularizer=tf.keras.regularizers.l1(valreg),\n",
    "    activity_regularizer=tf.keras.regularizers.l2(valreg),\n",
    "    kernel_initializer=tf.random_uniform_initializer(),\n",
    "    bias_initializer = tf.random_uniform_initializer())\n",
    "\n",
    "    def call(self, input):\n",
    "        feat = tf.nn.relu(self.l1(input))\n",
    "        #feat = tf.nn.dropout(feat, rate=0.01)\n",
    "        feat = tf.nn.relu(self.l2(feat))\n",
    "        feat = tf.nn.relu(self.l3(feat))\n",
    "        feat = tf.nn.relu(self.l4(feat))\n",
    "        feat = self.l5(feat)\n",
    "        return feat\n",
    "        \n",
    "    def predict(self, history_one):\n",
    "        inp = np.expand_dims(history_one, axis=0)\n",
    "        return np.squeeze(self(inp).numpy())\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataset(size_dataset=10**3, splits=1):\n",
    "    dataset = []\n",
    "    labels=[]\n",
    "    for i in range(size_dataset):\n",
    "        ph = np.random.choice([-1.,1.],1)[0]\n",
    "        b = -.7\n",
    "\n",
    "        p0 = Prob(ph*0.4, b, 0)\n",
    "        outcome = np.random.choice([0.,1.], 1, p=[p0,1-p0])[0]\n",
    "        labels.append(int(ph+1)/2)\n",
    "        dataset.append([outcome])\n",
    "    dataset = np.split(np.array(dataset), splits+(len(dataset)%splits ))\n",
    "    labels = np.split(np.array(labels), splits+(len(labels)%splits ))\n",
    "    for i,k in enumerate(labels):\n",
    "        labels[i] = tf.convert_to_tensor(k)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.693, Accuracy: 49.800%\n",
      "Epoch 005: Loss: 0.693, Accuracy: 49.800%\n",
      "Epoch 010: Loss: 0.693, Accuracy: 49.800%\n",
      "Epoch 015: Loss: 0.683, Accuracy: 81.000%\n",
      "Epoch 020: Loss: 0.561, Accuracy: 81.000%\n",
      "Epoch 025: Loss: 0.475, Accuracy: 81.000%\n",
      "Epoch 030: Loss: 0.475, Accuracy: 81.000%\n",
      "Epoch 035: Loss: 0.475, Accuracy: 81.000%\n",
      "Epoch 040: Loss: 0.475, Accuracy: 81.000%\n",
      "Epoch 045: Loss: 0.475, Accuracy: 81.000%\n"
     ]
    }
   ],
   "source": [
    "data, label = createdataset(10**3,10)\n",
    "\n",
    "lossfunction = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=10**-3)\n",
    "q2 = Q2()\n",
    "\n",
    "def givemeloss(model, x, y, training=False):\n",
    "    y_ = model(x, training=training)\n",
    "    return lossfunction(y_true = y, y_pred = y_)\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    for k in range(len(data)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(q2.trainable_variables)\n",
    "            loss = givemeloss(q2, data[k], label[k])\n",
    "            grads = tape.gradient(loss, q2.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, q2.trainable_variables))\n",
    "        epoch_loss_avg(loss)\n",
    "        epoch_accuracy(label[k], q2(data[k]))\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.684, Accuracy: 59.400%\n",
      "Epoch 005: Loss: 0.500, Accuracy: 79.300%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.76126885 0.23873115]], shape=(1, 2), dtype=float64)\n",
      "tf.Tensor([[0.11962863 0.88037137]], shape=(1, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for ot in [0., 1.]:\n",
    "    print(tf.nn.softmax(q2(np.array([[ot]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8, 24, 34, 46, 47, 48]),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.argmax(q2(data[0]),axis=1)-label[0].numpy() == -1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff =np.argmax(tf.nn.softmax(q2.predict(data[0])),axis=1) - label[0].numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 6, 36]),)\n",
      "(array([ 5, 23, 26, 29, 31, 34, 45, 46, 50, 53, 78, 83, 86, 87]),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(diff == 1.))\n",
    "print(np.where(diff == -1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[data[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][np.where(diff == -1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0].numpy()[np.where(diff == -1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tf.nn.softmax(q2(np.array([[0.]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75398872 0.24601128]\n"
     ]
    }
   ],
   "source": [
    "b=-.7\n",
    "outcome=0\n",
    "po1=np.sum([Prob(pp*0.4,b,outcome) for pp in [-1,1]])\n",
    "print(np.array([Prob(k*0.4, b, outcome) for k in [-1,1]])/po1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10924219 0.89075781]\n"
     ]
    }
   ],
   "source": [
    "b=-.7\n",
    "outcome=1\n",
    "po1=np.sum([Prob(pp*0.4,b,outcome) for pp in [-1,1]])\n",
    "print(np.array([Prob(k*0.4, b, outcome) for k in [-1,1]])/po1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Okay it's fine that accuracy is not the 100 porque i could send -1 and obtain outcome 1 with some probability!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19213304707932957"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actually, with this probability:\n",
    "(Prob(-0.4,b,1) + Prob(0.4,b,0)   )/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahi lo tenés papá"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
